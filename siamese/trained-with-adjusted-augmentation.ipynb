{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"!pip install fastai --upgrade\nfrom fastai.vision.all import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.vision.all import *\nfrom fastai.callback.all import *\nfrom fastai.basics import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path('../input/covid19-radiography-database/COVID-19 Radiography Database')\npath.ls()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = get_image_files(path)\nlen(files)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import PIL\nimg = PIL.Image.open(files[0])\nimg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport numpy as np\n\ndef open_image(fname, size=224):\n    img = PIL.Image.open(fname).convert('RGB')\n    img = img.resize((size, size))\n    t = torch.Tensor(np.array(img))\n    return t.permute(2,0,1).float()/255.0\n\nopen_image(files[0]).shape\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef label_func(fname):\n    return fname.parent.name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_func(files[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = list(set(files.map(label_func)))\nlen(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lbl2files = {l: [f for f in files if label_func(f) == l] for l in labels}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n\nclass SiameseDataset(torch.utils.data.Dataset):\n    def __init__(self, files, is_valid=False):\n        self.files,self.is_valid = files,is_valid\n        if is_valid: self.files2 = [self._draw(f) for f in files]\n        \n    def __getitem__(self, i):\n        file1 = self.files[i]\n        (file2,same) = self.files2[i] if self.is_valid else self._draw(file1)\n        img1,img2 = open_image(file1),open_image(file2)\n        return (img1, img2, torch.Tensor([same]).squeeze())\n    \n    def __len__(self): return len(self.files)\n    \n    def _draw(self, f):\n        same = random.random() < 0.5\n        cls = label_func(f)\n        if not same: cls = random.choice([l for l in labels if l != cls]) \n        return random.choice(lbl2files[cls]),same","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idxs = np.random.permutation(range(len(files)))\ncut = int(0.8 * len(files))\ntrain_files = files[idxs[:cut]]\nvalid_files = files[idxs[cut:]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = SiameseDataset(train_files)\nvalid_ds = SiameseDataset(valid_files, is_valid=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.data.core import DataLoaders","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dls = DataLoaders.from_dsets(train_ds, valid_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"b = dls.one_batch()\ndls = dls.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SiameseModel(Module):\n    def __init__(self, encoder, head):\n        self.encoder,self.head = encoder,head\n    \n    def forward(self, x1, x2):\n        ftrs = torch.cat([self.encoder(x1), self.encoder(x2)], dim=1)\n        return self.head(ftrs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_meta[resnet34]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = create_body(resnet34, cut=-2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"head = create_head(512*4, 2, ps=0.5)\nmodel = SiameseModel(encoder, head)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def siamese_splitter(model):\n    return [params(model.encoder), params(model.head)]\n\ndef loss_func(out, targ):\n    return CrossEntropyLossFlat()(out, targ.long())\n\nclass SiameseImage(fastuple):\n    def show(self, ctx=None, **kwargs): \n        if len(self) > 2:\n            img1,img2,similarity = self\n        else:\n            img1,img2 = self\n            similarity = 'Undetermined'\n        if not isinstance(img1, Tensor):\n            if img2.size != img1.size: img2 = img2.resize(img1.size)\n            t1,t2 = tensor(img1),tensor(img2)\n            t1,t2 = t1.permute(2,0,1),t2.permute(2,0,1)\n        else: t1,t2 = img1,img2\n        line = t1.new_zeros(t1.shape[0], t1.shape[1], 10)\n        return show_image(torch.cat([t1,line,t2], dim=2), title=similarity, ctx=ctx, **kwargs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SiameseTransform(Transform):\n    def __init__(self, files, splits):\n        self.valid = {f: self._draw(f) for f in files[splits[1]]}\n        \n    def encodes(self, f):\n        f2,t = self.valid.get(f, self._draw(f))\n        img1,img2 = PILImage.create(f),PILImage.create(f2)\n        return SiameseImage(img1, img2, int(t))\n    \n    def _draw(self, f):\n        same = random.random() < 0.5\n        cls = label_func(f)\n        if not same: cls = random.choice(L(l for l in labels if l != cls)) \n        return random.choice(lbl2files[cls]),same","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"splits = RandomSplitter()(files)\ntfm = SiameseTransform(files, splits)\ntls = TfmdLists(files, tfm, splits=splits)\ndls = tls.dataloaders(after_item=[Resize(224), ToTensor], \n                      after_batch=[IntToFloatTensor,Rotate(max_deg=45, p=1.),\n                                   Brightness(max_lighting=0.2, p=1.),RandomErasing(p=1., max_count=10, min_aspect=0.5, sl=0.2, sh=0.2),Warp(magnitude=0.2, p=1.0),Normalize.from_stats(*imagenet_stats)])","execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'RandomSplitter' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-fda69fe2a14e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSplitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtfm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSiameseTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfmdLists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtfm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m dls = tls.dataloaders(after_item=[Resize(224), ToTensor], \n\u001b[1;32m      5\u001b[0m                       after_batch=[IntToFloatTensor,Rotate(max_deg=45, p=1.),\n","\u001b[0;31mNameError\u001b[0m: name 'RandomSplitter' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics = [accuracy, F1Score(), Precision(), Recall()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), splitter=siamese_splitter, metrics=metrics)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.freeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(4, 1e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(4, slice(3e-4,4e-3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@typedispatch\ndef show_results(x:SiameseImage, y, samples, outs, ctxs=None, max_n=6, nrows=None, ncols=2, figsize=None, **kwargs):\n    if figsize is None: figsize = (ncols*6, max_n//ncols * 3)\n    if ctxs is None: ctxs = get_grid(min(x[0].shape[0], max_n), nrows=None, ncols=ncols, figsize=figsize)\n    for i,ctx in enumerate(ctxs): \n        title = f'Actual: {[\"Not similar\",\"Similar\"][x[2][i].item()]} \\n Prediction: {[\"Not similar\",\"Similar\"][y[2][i].item()]}'\n        SiameseImage(x[0][i], x[1][i], title).show(ctx=ctx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.show_results()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}